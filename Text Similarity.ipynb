{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4231411a",
      "metadata": {
        "id": "4231411a"
      },
      "source": [
        "# Text Similarity and Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e1caa78",
      "metadata": {
        "id": "2e1caa78"
      },
      "source": [
        "Previous weeks have covered several techniques of analyzing text and extracting interesting insights. We have looked at supervised machine learning (ML) techniques that are used to classify or categorize text documents into several pre-assumed categories."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad46e04",
      "metadata": {
        "id": "6ad46e04"
      },
      "source": [
        "Today, we will be looking at several other techniques and use-cases that leverage unsupervised learning and information retrieval concepts, mainly, understanding text similarity and clustering. We will discuss some important concepts related to information retrieval, document similarity measures, and machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8531d37",
      "metadata": {
        "id": "b8531d37"
      },
      "source": [
        "One constraint in text classification is that we need some training data with manually labeled categories because we use supervised learning algorithms to build our classification model. The efforts of building this dataset are definitely not easy, because to build a good model, you need a sizeable amount of training data. For this, we need to spend time and manual effort in labeling data, building a model, and then finally using it to classify new documents. Can we instead make the machine do it? Yes, as a matter of fact, we can. This chapter specifically addresses looking at the content of text documents, analyzing their similarity using various measures, and clustering similar documents together."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab4401a",
      "metadata": {
        "id": "8ab4401a"
      },
      "source": [
        "Text data is unstructured and highly noisy. We get the benefits of well-labeled training data and supervised learning when performing text classification. But document clustering is an unsupervised learning process, where we are trying to segment and categorize documents into separate categories by making the machine learn about the various text documents, their features, similarities, and the differences among them. This makes document clustering more challenging, albeit interesting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8691063c",
      "metadata": {
        "id": "8691063c"
      },
      "source": [
        "We will focus on several concepts related to text similarity, distance metrics, and unsupervised ML algorithms to answer the following questions\n",
        "<ul>\n",
        "<li>How do we measure similarity between documents?</li>\n",
        "<li>How can we use distance measures to find the most relevant documents?</li>\n",
        "<li>When is a distance measure called a metric?</li>\n",
        "<li>How do we cluster or group similar documents?</li>\n",
        "<li>Can we visualize document clusters?</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e46f129",
      "metadata": {
        "id": "0e46f129"
      },
      "source": [
        "## Information Retrieval (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f12cbce",
      "metadata": {
        "id": "6f12cbce"
      },
      "source": [
        "Information retrieval (IR) is the process of retrieving or fetching relevant sources of information from a corpus or set of entities that hold information based on some demand. For example, it could be a query or search that users enter in a search engine and then get relevant search items pertaining to their query. In fact, search engines are the most popular use-case or application of IR."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbbcb64d",
      "metadata": {
        "id": "bbbcb64d"
      },
      "source": [
        "The relevancy of documents with information compared to the demand can be measured in several ways. It can include looking for specific keywords from the search text or using some similarity measures to see the similarity rank or score of the documents with respect to the entered query. This makes is quite different from string matching or matching regular expressions because more than often the words in a search string can have different order, context, and semantics in the collection of documents (entities), and these words can even have multiple different resolutions or possibilities based on synonyms, antonyms, and negation modifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174e9084",
      "metadata": {
        "id": "174e9084"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89835f10",
      "metadata": {
        "id": "89835f10"
      },
      "source": [
        "Feature engineering or feature extraction is something which you know quite well by now. Methods like Bag of Words, TF-IDF, and word vectorization models are typically used to represent or model documents in the form of numeric vectors so that applying mathematical or machine learning techniques become much easier. You can use various document representations using these feature-extraction techniques or even map each letter or a word to a corresponding unique numeric identifier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99623c92",
      "metadata": {
        "id": "99623c92"
      },
      "source": [
        "## Similarity Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a4537f",
      "metadata": {
        "id": "58a4537f"
      },
      "source": [
        "Similarity measures are used frequently in text similarity analysis and clustering. Any similarity or distance measure usually measures the degree of closeness between two entities, which can be any text format like documents, sentences, or even terms. This measure of similarity can be useful in identifying similar entities and distinguishing clearly different entities from each other. Similarity measures are very effective, and sometimes choosing the right measure can make a lot of difference in the performance of your final analytics system. Various scoring or ranking algorithms have also been invented based on these distance measures."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac15198",
      "metadata": {
        "id": "fac15198"
      },
      "source": [
        "There are several distance measures that measure similarity, and we will be covering several of them. However, an important thing to remember is that all distance measures of similarity are not distance metrics of similarity.\n",
        "\n",
        "Consider a distance measure <code>d</code> and two entities (say they are documents in our context) <code>x</code> and <code>y</code>. The distance between x and y, which is used to determine the degree of similarity between them, can be represented as <code>d(x, y)</code>, but the measure d can be called as a distance metric of similarity if and only if it satisfies the following four conditions:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b831894f",
      "metadata": {
        "id": "b831894f"
      },
      "source": [
        "<ol>\n",
        "<li>The distance measured between any two entities, say x and y, must be always non-negative, that is, d(x, y) $\\geq$ 0</li>\n",
        "<li>The distance between two entities should always be zero if and only if they are both identical, that is, d(x, y) $\\geq$ 0 <i>iff</i> x=y</li>\n",
        "<li>This distance measure should always be symmetric, which means that the distance from x to y is always the same as the\n",
        "distance from <code>y</code> to <code>x</code>. Mathematically this is represented as <code>d(x, y) = d(y, x)</code></li>\n",
        "<li>This distance measure should satisfy the triangle inequality property, which can be mathematically represented\n",
        "    d(x, z) $\\leq$ d(x, y) + d(y, z)\n",
        "    </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcd0ef1e",
      "metadata": {
        "id": "dcd0ef1e"
      },
      "source": [
        "## Unsupervised Machine Learning Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bcbeb9c",
      "metadata": {
        "id": "3bcbeb9c"
      },
      "source": [
        "<code>Unsupervised machine learning algorithms</code> are the family of ML algorithms that try to discover latent hidden structures and patterns in data from their various attributes and features. Besides this, several unsupervised learning algorithms are also used to reduce the feature space, which is often of a higher dimension to one with a lower dimension. The data on which these algorithms operate is essentially unlabeled data that does not have any pre-determined category or class. We apply these algorithms with the intent of finding patterns and distinguishing features that might help us in grouping various data points into groups or clusters. These algorithms are popularly known as <code>clustering algorithms</code>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76added5",
      "metadata": {
        "id": "76added5"
      },
      "source": [
        "### Text Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4f961b",
      "metadata": {
        "id": "7d4f961b"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b1b0d12",
      "metadata": {
        "id": "4b1b0d12"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
        "    feature_type = feature_type.lower().strip()\n",
        "\n",
        "    if feature_type == 'binary':\n",
        "        vectorizer = CountVectorizer(binary=True, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    elif feature_type == 'frequency':\n",
        "        vectorizer = CountVectorizer(binary=False, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    elif feature_type == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Wrong feature type entered. Possible values:'binary', 'frequency','tfidf'\")\n",
        "\n",
        "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
        "    return vectorizer, feature_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21488b5e",
      "metadata": {
        "id": "21488b5e"
      },
      "source": [
        "You can see from the function definition that we have capabilities for Bag of Words frequency, occurrences, and also TF-IDF–based features. The new additions in this function include the addition of the min_df, max_df, and ngram_range parameters and also accepting them as optional arguments. N-grams are contiguous sequences of \"n\" items, typically words.\n",
        "\n",
        "<ul>\n",
        "<li>ngram_range is useful when we want to add bigrams, trigrams, and so on as additional features.</li>\n",
        "<li>min_df parameter can be expressed by a threshold value within a range of [0.0, 1.0] and it will ignore terms as features that will have a document frequency strictly lower than the input threshold value.</li>    \n",
        "<li>max_df parameter can also be expressed by a threshold value within a range of [0.0, 1.0] and it will ignore terms as features that will have a document frequency strictly higher than the input threshold value. </li>\n",
        "</ul>\n",
        "\n",
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/grams.png?raw=1\" width=\"350\" height=\"200\">\n",
        "\n",
        "The intuition behind this would be that these words, if they occur in almost all the documents, tend to have little value that would help us in distinguishing among various types of documents.\n",
        "\n",
        "We will now deep dive into the various techniques for text similarity\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01088d3a",
      "metadata": {
        "id": "01088d3a"
      },
      "source": [
        "## Text Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95c01d6f",
      "metadata": {
        "id": "95c01d6f"
      },
      "source": [
        "The main objective of text similarity is to analyze and measure how two entities of text are close or far apart from each other. These entities of text can be simple tokens or terms, like words, or whole documents, which may include sentences or paragraphs of text. There are various ways of analyzing text similarity, and we can classify the intent of text similarity broadly into the following two areas:\n",
        "<ul>\n",
        "<li><code>Lexical similarity</code>: This involves observing the contents of the <code>text documents with regard to syntax, structure, and <b>content</b></code> and measuring their similarity based on these parameters</li>    \n",
        "<li><code>Semantic similarity</code>: This involves trying to find out the <code>semantics, meaning, and <b>context</b></code> of the documents and then trying to see how close they are to each other. Dependency grammars and entity recognition are handy tools that can help in this.</li>\n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "212e0d5b",
      "metadata": {
        "id": "212e0d5b"
      },
      "source": [
        "Note that the most popular area is lexical similarity, because the techniques are more straightforward, easy to implement, and you can also cover several parts of semantic similarity using simple models like the Bag of Words. Usually distance metrics will be used to measure similarity scores between text entities, and we will be mainly covering the following two broad areas of text similarity:\n",
        "<ul>\n",
        "<li><code>Term similarity</code>: Here we will measure similarity between individual tokens or words.</li>\n",
        "<li><code>Document similarity</code>: Here we will be measuring similarity between entire text documents.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c09113",
      "metadata": {
        "id": "84c09113"
      },
      "source": [
        "The idea is to implement and use several distance metrics and see how we can measure and analyze similarity among entities that are just simple words, and then how things change when we measure similarity among documents that are groups of individual words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e27e77",
      "metadata": {
        "id": "c6e27e77"
      },
      "source": [
        "### Term Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b219b6",
      "metadata": {
        "id": "d5b219b6"
      },
      "source": [
        "<code>Term similarity</code>: Measures similarity between individual tokens or words.\n",
        "\n",
        "Several applications and use-cases like autocompleters, spell check, and correctors use some of these techniques to correct misspelled terms.\n",
        "\n",
        "Here we will be taking a couple of words and measuring the similarity between then using different word representations as\n",
        "well as distance metrics. The word representations we will be using are as follows:\n",
        "\n",
        "<ul>\n",
        "<li>Character vectorization</li>\n",
        "<li>Bag of Characters vectorization</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82032af9",
      "metadata": {
        "id": "82032af9"
      },
      "source": [
        "####  Character vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46c6ceb2",
      "metadata": {
        "id": "46c6ceb2"
      },
      "source": [
        "Character vectorization is an extremely simple process of just mapping each character of the term to a corresponding unique number. We can do that using the function depicted in the following snippet: The function takes input a list of words or terms and returns the corresponding character vectors for the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c1ce1fdd",
      "metadata": {
        "id": "c1ce1fdd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def vectorize_terms(terms):\n",
        "    terms = [term.lower() for term in terms]\n",
        "    terms = [np.array(list(term)) for term in terms]\n",
        "    terms = [np.array([ord(char) for char in term]) for term in terms]\n",
        "    return terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02cc91c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02cc91c7",
        "outputId": "b97e6945-c796-49fe-a93d-46c1a77693a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([112]), array([101]), array([116])]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "vectorize_terms('pet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7abadb89-9600-4ed8-90e7-3f2b138f922a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7abadb89-9600-4ed8-90e7-3f2b138f922a",
        "outputId": "92ac2257-f03d-4f93-d256-c11f0cdec7e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([112]), array([111]), array([116])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "vectorize_terms('pot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4ba5017-1574-45ae-b024-5739e741468d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ba5017-1574-45ae-b024-5739e741468d",
        "outputId": "cc5ae065-283f-4150-e719-f10326caed64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([112]),\n",
              " array([111]),\n",
              " array([116]),\n",
              " array([97]),\n",
              " array([116]),\n",
              " array([111])]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "vectorize_terms('potato')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "996bc07f",
      "metadata": {
        "id": "996bc07f"
      },
      "outputs": [],
      "source": [
        "root = 'Believe'\n",
        "term1 = 'beleive'\n",
        "term2 = 'bargain'\n",
        "term3 = 'Elephan'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d7c194d6",
      "metadata": {
        "id": "d7c194d6"
      },
      "outputs": [],
      "source": [
        "terms = [root, term1, term2, term3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "37dad6fc",
      "metadata": {
        "id": "37dad6fc"
      },
      "outputs": [],
      "source": [
        "# Character vectorization\n",
        "vec_root, vec_term1, vec_term2, vec_term3 = vectorize_terms(terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe37d870",
      "metadata": {
        "id": "fe37d870",
        "outputId": "add6ff71-2b30-481e-e60c-c25529f1cdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root: [ 98 101 108 105 101 118 101] \n",
            "term1: [ 98 101 108 101 105 118 101] \n",
            "term2: [ 98  97 114 103  97 105 110] \n",
            "term3: [101 108 101 112 104  97 110]\n"
          ]
        }
      ],
      "source": [
        "print ('root: {} \\nterm1: {} \\nterm2: {} \\nterm3: {}'.format(vec_root, vec_term1, vec_term2,\n",
        "                                                             vec_term3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2488f8cd",
      "metadata": {
        "id": "2488f8cd"
      },
      "source": [
        "#### Bag of Characters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea291400",
      "metadata": {
        "id": "ea291400"
      },
      "source": [
        "Bag of Characters vectorization is very similar to the Bag of Words model except here we compute the frequency of each character in the word. Sequence or word orders are not taken into account. The following function helps in computing this.\n",
        "\n",
        "In that function, we take in a list of words or terms and then extract the unique characters from all the words. This becomes our feature list, just like we do in Bag of Words, where instead of characters, unique words are our features. Once we have this list of unique_chars, we get the count for each of the characters in each word and build our Bag of Characters vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "827cab0c",
      "metadata": {
        "id": "827cab0c"
      },
      "outputs": [],
      "source": [
        "#from scipy.stats import itemfreq\n",
        "import numpy as np\n",
        "def boc_term_vectors(word_list):\n",
        "    word_list = [word.lower() for word in word_list]\n",
        "    unique_chars = np.unique(np.hstack([list(word) for word in word_list]))\n",
        "    word_list_term_counts = [{char: count for char, count in zip(*np.unique(list(word), return_counts=True))} for word in word_list]\n",
        "    boc_vectors = [np.array([int(word_term_counts.get(char, 0)) for char in unique_chars]) for word_term_counts in word_list_term_counts]\n",
        "    return list(unique_chars), boc_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba64fdd",
      "metadata": {
        "id": "1ba64fdd",
        "outputId": "beeb727c-af84-462b-cee7-60a87a3fd3b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([np.str_(' '),\n",
              "  np.str_('a'),\n",
              "  np.str_('c'),\n",
              "  np.str_('e'),\n",
              "  np.str_('o'),\n",
              "  np.str_('p'),\n",
              "  np.str_('t')],\n",
              " [array([0, 0, 0, 0, 0, 1, 0]),\n",
              "  array([0, 0, 0, 1, 0, 0, 0]),\n",
              "  array([0, 0, 0, 0, 0, 0, 1]),\n",
              "  array([1, 0, 0, 0, 0, 0, 0]),\n",
              "  array([0, 0, 0, 0, 0, 1, 0]),\n",
              "  array([0, 0, 0, 0, 1, 0, 0]),\n",
              "  array([0, 0, 0, 0, 0, 0, 1]),\n",
              "  array([1, 0, 0, 0, 0, 0, 0]),\n",
              "  array([0, 0, 1, 0, 0, 0, 0]),\n",
              "  array([0, 1, 0, 0, 0, 0, 0]),\n",
              "  array([0, 0, 0, 0, 0, 0, 1])])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boc_term_vectors('pet pot cat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "de424499",
      "metadata": {
        "id": "de424499"
      },
      "outputs": [],
      "source": [
        "root = 'Believe'\n",
        "term1 = 'beleive'\n",
        "term2 = 'bargain'\n",
        "term3 = 'Elephan'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6599641c",
      "metadata": {
        "id": "6599641c"
      },
      "outputs": [],
      "source": [
        "terms = [root, term1, term2, term3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1d78ef3e",
      "metadata": {
        "id": "1d78ef3e"
      },
      "outputs": [],
      "source": [
        "# Bag of characters vectorization\n",
        "features, (boc_root, boc_term1, boc_term2, boc_term3) = boc_term_vectors(terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "07245333",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07245333",
        "outputId": "0fd657a3-d8d1-4aaa-a98a-4fe52ea80c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['a', 'b', 'e', 'g', 'h', 'i', 'l', 'n', 'p', 'r', 'v']\n",
            "root: [0 1 3 0 0 1 1 0 0 0 1] \n",
            "term1: [0 1 3 0 0 1 1 0 0 0 1] \n",
            "term2: [2 1 0 1 0 1 0 1 0 1 0] \n",
            "term3: [1 0 2 0 1 0 1 1 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "print ('Features:', features)\n",
        "print ('root: {} \\nterm1: {} \\nterm2: {} \\nterm3: {}'.format(boc_root, boc_term1, boc_term2, boc_term3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30cab13e",
      "metadata": {
        "id": "30cab13e"
      },
      "source": [
        "### Distance Metrics to Compute Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30956036",
      "metadata": {
        "id": "30956036"
      },
      "source": [
        "Thus you can see how we can easily transform text terms into numeric vector representations. We will now be using several distance metrics to compute similarity between the root word and the other three words mentioned in the preceding snippet. There are a lot of distance metrics out there that you can use to compute and measure similarities. We will be covering the following:\n",
        "<ul>\n",
        "<li>Hamming distance</li>\n",
        "<li>Manhattan distance</li>\n",
        "<li>Euclidean distance</li>\n",
        "<li>Levenshtein edit distance</li>\n",
        "<li>Cosine distance and similarity</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaec1d9d",
      "metadata": {
        "id": "eaec1d9d"
      },
      "source": [
        "We will set up some necessary variables storing the root term, the other terms with which its similarity will be measures, and their various vector representations using the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cbe23ab2",
      "metadata": {
        "id": "cbe23ab2"
      },
      "outputs": [],
      "source": [
        "root_term = root\n",
        "root_vector = vec_root\n",
        "root_boc_vector = boc_root\n",
        "terms = [term1, term2, term3]\n",
        "vector_terms = [vec_term1, vec_term2, vec_term3]\n",
        "boc_vector_terms = [boc_term1, boc_term2, boc_term3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4719b0f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4719b0f5",
        "outputId": "9a6573c3-6372-4f0c-caf4-872736de05e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Believe\n",
            "[ 98 101 108 105 101 118 101]\n",
            "[0 1 3 0 0 1 1 0 0 0 1]\n",
            "['beleive', 'bargain', 'Elephan']\n",
            "[array([ 98, 101, 108, 101, 105, 118, 101]), array([ 98,  97, 114, 103,  97, 105, 110]), array([101, 108, 101, 112, 104,  97, 110])]\n",
            "[array([0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 1]), array([2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]), array([1, 0, 2, 0, 1, 0, 1, 1, 1, 0, 0])]\n"
          ]
        }
      ],
      "source": [
        "print(root_term)\n",
        "print(root_vector)\n",
        "print(root_boc_vector)\n",
        "print(terms)\n",
        "print(vector_terms)\n",
        "print(boc_vector_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71112a2c",
      "metadata": {
        "id": "71112a2c"
      },
      "source": [
        "We are now ready to start computing similarity metrics and will be using the preceding terms and their vector representations to measure similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a0645d",
      "metadata": {
        "id": "b9a0645d"
      },
      "source": [
        "#### Hamming Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935a80f3",
      "metadata": {
        "id": "935a80f3"
      },
      "source": [
        "The Hamming distance is a very popular distance metric used frequently in information theory and communication systems. It is distance measured between two strings under the assumption that they are of equal length. Formally, it is defined as the number of positions that have different characters or symbols between two strings of equal length. Considering two terms u and v of length n, we can mathematically denote Hamming distance as:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a0bb38",
      "metadata": {
        "id": "e2a0bb38"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm1.png?raw=1\" width=\"200\" height=\"150\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281b1f6a",
      "metadata": {
        "id": "281b1f6a"
      },
      "source": [
        "and you can also normalize it if you want by dividing the number of mismatches by the total length of the terms to give the normalized hamming distance, which is represented as:\n",
        "\n",
        "whereas you already know n denotes the length of the terms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4bc722",
      "metadata": {
        "id": "9c4bc722"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm2.png?raw=1\" width=\"250\" height=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6007c54f",
      "metadata": {
        "id": "6007c54f"
      },
      "source": [
        "The following function computes the Hamming distance between two terms and also has the capability to compute the normalized distance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "381cc8c6",
      "metadata": {
        "id": "381cc8c6"
      },
      "outputs": [],
      "source": [
        "def hamming_distance(u, v, norm=False):\n",
        "    if u.shape != v.shape:\n",
        "        raise ValueError('The vectors must have equal lengths.')\n",
        "    return (u != v).sum() if not norm else (u != v).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "880d0a53",
      "metadata": {
        "id": "880d0a53"
      },
      "source": [
        "We will now measure the Hamming distance between our root term and the other terms using the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d9570416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9570416",
        "outputId": "59db7ed7-af9e-486c-d4a7-02100a5cc2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamming distance between root: Believe and term: beleive is 2\n",
            "Hamming distance between root: Believe and term: bargain is 6\n",
            "Hamming distance between root: Believe and term: Elephan is 7\n"
          ]
        }
      ],
      "source": [
        "# compute Hamming distance\n",
        "for term, vector_term in zip(terms, vector_terms):\n",
        "    print('Hamming distance between root: {} and term: {} is {}'\n",
        "          .format(root_term,term,hamming_distance(root_vector, vector_term, norm=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9d25bf7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d25bf7e",
        "outputId": "df195069-949c-4f93-8454-be8ee4a15827"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 98, 101, 108, 101, 105, 118, 101]),\n",
              " array([ 98,  97, 114, 103,  97, 105, 110]),\n",
              " array([101, 108, 101, 112, 104,  97, 110])]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vector_terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "712daf57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "712daf57",
        "outputId": "0b4da6eb-c271-4331-b0a2-ecad68dc7ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Hamming distance between root: Believe and term: beleive is 0.29\n",
            "Normalized Hamming distance between root: Believe and term: bargain is 0.86\n",
            "Normalized Hamming distance between root: Believe and term: Elephan is 1.0\n"
          ]
        }
      ],
      "source": [
        "# compute normalized Hamming distance\n",
        "for term, vector_term in zip(terms, vector_terms):\n",
        "    print('Normalized Hamming distance between root: {} and term: {} is {}'\n",
        "          .format(root_term,term,round(hamming_distance(root_vector, vector_term, norm=True), 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "716e6112",
      "metadata": {
        "id": "716e6112"
      },
      "source": [
        "You can see from the preceding output that terms 'Believe' and 'believe' ignoring their case are most similar to each other with the Hamming distance of 2 or 0.29, compared to the term 'bargain' giving scores of 6 or 0.86 (here, the smaller the score, the more similar are the terms). The term 'Elephant' throws an exception because the length of that term (term3) is 8 compared to length 7 of the root term 'Believe', hence Hamming distance can’t be computed because the base assumption of strings being of equal length is violated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d503b60a",
      "metadata": {
        "id": "d503b60a"
      },
      "source": [
        "#### Manhattan Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf51ab61",
      "metadata": {
        "id": "bf51ab61"
      },
      "source": [
        "The Manhattan distance metric is similar to the Hamming distance conceptually, where instead of counting the number of mismatches, we subtract the difference between each pair of characters at each position of the two strings. Formally, Manhattan distance is also known as city block distance, L1 norm, taxicab metric and is defined as the distance between two points in a grid based on strictly horizontal or vertical paths instead of the diagonal distance conventionally calculated by the Euclidean distance metric. Mathematically it can be denoted as"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0aa40e",
      "metadata": {
        "id": "6d0aa40e"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm3.png?raw=1\" width=\"200\" height=\"150\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c22c4c",
      "metadata": {
        "id": "b0c22c4c"
      },
      "source": [
        "where u and v are the two terms of length n. The same assumption of the two terms having equal length from Hamming distance holds good here. We can also compute the normalized Manhattan distance by dividing the sum of the absolute differences by the term length. This can be denoted by"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81100e20",
      "metadata": {
        "id": "81100e20"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm4.png?raw=1\" width=\"230\" height=\"170\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2eae43d",
      "metadata": {
        "id": "a2eae43d"
      },
      "source": [
        "where n is the length of each of the terms u and v. The following function helps us in implementing Manhattan distance with the capability to also compute the normalized Manhattan distance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a3cc0fc0",
      "metadata": {
        "id": "a3cc0fc0"
      },
      "outputs": [],
      "source": [
        "def manhattan_distance(u, v, norm=False):\n",
        "    if u.shape != v.shape:\n",
        "        raise ValueError('The vectors must have equal lengths.')\n",
        "    return abs(u - v).sum() if not norm else abs(u - v).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826d9254",
      "metadata": {
        "id": "826d9254"
      },
      "source": [
        "We will now compute the Manhattan distance between our root term and the other terms using the previous function, as shown in the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "62ebea88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ebea88",
        "outputId": "5b6f0a01-f964-4450-d870-189e5ae72d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manhattan distance between root: Believe and term: beleive is 8\n",
            "Manhattan distance between root: Believe and term: bargain is 38\n",
            "Manhattan distance between root: Believe and term: Elephan is 57\n"
          ]
        }
      ],
      "source": [
        "for term, vector_term in zip(terms, vector_terms):\n",
        "    print('Manhattan distance between root: {} and term: {} is {}'\n",
        "          .format(root_term,term, manhattan_distance(root_vector,vector_term, norm=False)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bd6a1cee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd6a1cee",
        "outputId": "a6c34dc7-cf63-4e7f-b014-fbfdc09bd5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Manhattan distance between root: Believe and term: beleive is 1.14\n",
            "Normalized Manhattan distance between root: Believe and term: bargain is 5.43\n",
            "Normalized Manhattan distance between root: Believe and term: Elephan is 8.14\n"
          ]
        }
      ],
      "source": [
        "# compute normalized Manhattan distance\n",
        "for term, vector_term in zip(terms, vector_terms):\n",
        "    print('Normalized Manhattan distance between root: {} and term: {} is {}'\n",
        "          .format(root_term,term,round(manhattan_distance(root_vector, vector_term,norm=True),2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06cf64c",
      "metadata": {
        "id": "c06cf64c"
      },
      "source": [
        "From those results you can see that as expected, the distance between 'Believe' and 'believe' ignoring their case is most similar to each other, with a score of 8 or 1.14, as compared to 'bargain', which gives a score of 38 or 5.43 (here the smaller the score, the more similar the words). The term 'Elephant' yields an error because it has a different length compared to the base term just as we noticed earlier when computing Hamming distances."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985f6857",
      "metadata": {
        "id": "985f6857"
      },
      "source": [
        "#### Euclidean Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a04dbe48",
      "metadata": {
        "id": "a04dbe48"
      },
      "source": [
        "We briefly mentioned the Euclidean distance when comparing it with the Manhattan distance in the earlier section. Formally, the Euclidean distance is also known as the Euclidean norm, L2 norm, or L2 distance and is defined as the shortest straight-line distance between two points. Mathematically this can be denoted as"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a77b4e2",
      "metadata": {
        "id": "8a77b4e2"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm5.png?raw=1\" width=\"230\" height=\"170\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edda2f33",
      "metadata": {
        "id": "edda2f33"
      },
      "source": [
        "where the two points u and v are vectorized text terms in our scenario, each having length n. The following function helps us in computing the Euclidean distance between two terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b069186",
      "metadata": {
        "id": "2b069186"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(u, v):\n",
        "    if u.shape != v.shape:\n",
        "        raise ValueError('The vectors must have equal lengths.')\n",
        "    distance = np.sqrt(np.sum(np.square(u - v)))\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed983f18",
      "metadata": {
        "id": "ed983f18"
      },
      "source": [
        "We can now compare the Euclidean distance among our terms by using the preceding function as depicted in the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185991e7",
      "metadata": {
        "id": "185991e7",
        "outputId": "242855a0-7076-4b13-feed-145e4a666503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Euclidean distance between root: Believe and term: beleive is 5.66\n",
            "Euclidean distance between root: Believe and term: bargain is 17.94\n",
            "Euclidean distance between root: Believe and term: Elephan is 26.21\n"
          ]
        }
      ],
      "source": [
        "for term, vector_term in zip(terms, vector_terms):\n",
        "    print('Euclidean distance between root: {} and term: {} is {}'\n",
        "          .format(root_term,term, round(euclidean_distance(root_vector, vector_term),2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1608a56",
      "metadata": {
        "id": "c1608a56"
      },
      "source": [
        "From the preceding outputs you can see that the terms 'Believe' and 'believe' are the most similar with a score of 5.66 compared to 'bargain' giving us a score of 17.94, and 'Elephant' throws a ValueError because the base assumption that strings being compared should have equal lengths holds good for this distance metric also."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41f78cff",
      "metadata": {
        "id": "41f78cff"
      },
      "source": [
        "<b>Disclaimer:</b> So far, all the distance metrics we have used work on strings or terms of the same length and fail when they are not of equal length. So how do we deal with this problem? We will now look at a couple of distance metrics that work even with strings of unequal length to measure similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e71ff4e9",
      "metadata": {
        "id": "e71ff4e9"
      },
      "source": [
        "#### Levenshtein Edit Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bddccd",
      "metadata": {
        "id": "c6bddccd"
      },
      "source": [
        "The Levenshtein edit distance, often known as just Levenshtein distance, belongs to the family of edit distance–based metrics and is used to measure the distance between two sequence of strings based on their differences—similar to the concept behind Hamming distance. The Levenshtein edit distance between two terms can be defined as the minimum number of edits needed in the form of additions, deletions, or substitutions to change or convert one term to the other. These substitutions are character-based substitutions, where a single character can be edited in a single operation. Also, as mentioned before, the length of the two terms need not be equal here. Mathematically, we can represent the Levenshtein edit distance between u and v are our two terms where |u| and |v| are their lengths, in the formulae below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2bb607",
      "metadata": {
        "id": "8e2bb607"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm6.png?raw=1\" width=\"450\" height=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8cd520",
      "metadata": {
        "id": "ed8cd520"
      },
      "source": [
        "where i and j are basically indices for the terms u and v. The third equation in the minimum above has a cost function denoted by $C_{u_i \\neq u_j}$ such that it has the following conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e2994f",
      "metadata": {
        "id": "18e2994f"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm7.png?raw=1\" width=\"230\" height=\"170\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "943606ce",
      "metadata": {
        "id": "943606ce"
      },
      "source": [
        "and this denotes the indicator function, which depicts the cost associated with twocharacters being matched for the two terms (the equation represents the match or mismatch operation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b130e0a0",
      "metadata": {
        "id": "b130e0a0"
      },
      "source": [
        "The first equation in the previous minimum stands for the deletion operation, and the second equation represents the insertion operation. The function $ld_{u,v}(i, j)$ thus covers all the three operations of insertion, deletion, and addition as we mentioned earlier and it denotes the Levenshtein distance as measured between the first i characters for the term u and the first j characters of the term v. There are also several interesting boundary conditions with regard to the Levenshtein edit distance:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93767258",
      "metadata": {
        "id": "93767258"
      },
      "source": [
        "<ul>\n",
        "<li>The minimum value that the edit distance between two terms can take is the difference in length of the two terms</li>\n",
        "<li>The maximum value of the edit distance between two terms can be the length of the term that is larger.</li>\n",
        "<li>If the two terms are equal, the edit distance is zero.</li>\n",
        "<li>Hamming distance between two terms is an upper bound for Levenshtein edit distance if and only if the two terms have equal length.</li>\n",
        "<li>This being a distance metric also satisfies the triangle inequality property, discussed earlier when we talked about distance metrics.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2225b00b",
      "metadata": {
        "id": "2225b00b"
      },
      "source": [
        "There are various ways of implementing Levenshtein distance computations for terms. Here we will start with an example of two of our terms. Considering the root term 'believe' and another term 'beleive' (we ignore case in our computations). The edit distance would be 2 because we would need the following two operations:\n",
        "<ul>\n",
        "<li>'beleive' → 'beliive' (substitution of e to i)</li>\n",
        "<li>'beliive' → 'believe' (substitution of i to e)</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60085519",
      "metadata": {
        "id": "60085519"
      },
      "source": [
        "To implement this, we build a matrix that will basically compute the Levenshtein distance between all the characters of both terms by comparing each character of the first term with the characters of the second term. For computation, we follow a dynamic programming approach to get the edit distance between the two terms based on the last computed value. For the given two terms, the Levenshtein edit distance matrix our algorithm should generate is shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111c9535",
      "metadata": {
        "id": "111c9535"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm8.png?raw=1\" width=\"530\" height=\"470\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbd8a5d",
      "metadata": {
        "id": "1cbd8a5d"
      },
      "source": [
        "You can see in Figure 6-1 that the edit distances are computed for each pair of characters in the terms, as mentioned earlier, and the final edit distance value highlighted in the figure gives us the actual edit distance between the two terms. This algorithm is also known as the Wagner-Fischer algorithm and is available in the paper by R. Wagner and M. Fischer titled “The String-to-String Correction Problem,” which you can refer to if you are more interested in the details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1986002f",
      "metadata": {
        "id": "1986002f"
      },
      "source": [
        "The following function implements Levenshtein edit distance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5eb0e9f",
      "metadata": {
        "id": "a5eb0e9f"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f48f0cb",
      "metadata": {
        "id": "4f48f0cb"
      },
      "outputs": [],
      "source": [
        "def levenshtein_edit_distance(u, v):\n",
        "    # convert to lower case\n",
        "    u = u.lower()\n",
        "    v = v.lower()\n",
        "    # base cases\n",
        "    if u == v: return 0\n",
        "    elif len(u) == 0: return len(v)\n",
        "    elif len(v) == 0: return len(u)\n",
        "    # initialize edit distance matrix\n",
        "    edit_matrix = []\n",
        "    # initialize two distance matrices\n",
        "    du = [0] * (len(v) + 1)\n",
        "    dv = [0] * (len(v) + 1)\n",
        "    # du: the previous row of edit distance\n",
        "\n",
        "    for i in range(len(du)):\n",
        "        du[i] = i\n",
        "    # dv : the current row of edit distances\n",
        "    for i in range(len(u)):\n",
        "        dv[0] = i + 1\n",
        "        # compute cost as per algorithm\n",
        "        for j in range(len(v)):\n",
        "            cost = 0 if u[i] == v[j] else 1\n",
        "            dv[j + 1] = min(dv[j] + 1, du[j + 1] + 1, du[j] + cost)\n",
        "        # assign dv to du for next iteration\n",
        "        for j in range(len(du)):\n",
        "            du[j] = dv[j]\n",
        "        # copy dv to the edit matrix\n",
        "        edit_matrix.append(copy.copy(dv))\n",
        "    # compute the final edit distance and edit matrix\n",
        "    distance = dv[len(v)]\n",
        "    edit_matrix = np.array(edit_matrix)\n",
        "    edit_matrix = edit_matrix.T\n",
        "    edit_matrix = edit_matrix[1:,]\n",
        "    edit_matrix = pd.DataFrame(data=edit_matrix, index=list(v), columns=list(u))\n",
        "    return distance, edit_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a07701",
      "metadata": {
        "id": "51a07701"
      },
      "source": [
        "That function returns both the final Levenshtein edit distance and the complete edit matrix between the two terms u and v, which are taken as input. Remember, we need to pass the terms directly in their raw string format and not their vector representations. Also, we do not consider case of strings here and convert them to lowercase."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcfd06e",
      "metadata": {
        "id": "ebcfd06e"
      },
      "source": [
        "The following snippet computes the Levenshtein edit distance between our example terms using the preceding function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa83cb01",
      "metadata": {
        "id": "fa83cb01",
        "outputId": "2760695c-cac7-464c-e701-f79c53eaf802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing distance between root: Believe and term: beleive\n",
            "Levenshtein edit distance is 2\n",
            "The complete edit distance matrix is depicted below\n",
            "   b  e  l  i  e  v  e\n",
            "b  0  1  2  3  4  5  6\n",
            "e  1  0  1  2  3  4  5\n",
            "l  2  1  0  1  2  3  4\n",
            "e  3  2  1  1  1  2  3\n",
            "i  4  3  2  1  2  2  3\n",
            "v  5  4  3  2  2  2  3\n",
            "e  6  5  4  3  2  3  2\n",
            "------------------------------\n",
            "Computing distance between root: Believe and term: bargain\n",
            "Levenshtein edit distance is 6\n",
            "The complete edit distance matrix is depicted below\n",
            "   b  e  l  i  e  v  e\n",
            "b  0  1  2  3  4  5  6\n",
            "a  1  1  2  3  4  5  6\n",
            "r  2  2  2  3  4  5  6\n",
            "g  3  3  3  3  4  5  6\n",
            "a  4  4  4  4  4  5  6\n",
            "i  5  5  5  4  5  5  6\n",
            "n  6  6  6  5  5  6  6\n",
            "------------------------------\n",
            "Computing distance between root: Believe and term: Elephan\n",
            "Levenshtein edit distance is 6\n",
            "The complete edit distance matrix is depicted below\n",
            "   b  e  l  i  e  v  e\n",
            "e  1  1  2  3  4  5  6\n",
            "l  2  2  1  2  3  4  5\n",
            "e  3  2  2  2  2  3  4\n",
            "p  4  3  3  3  3  3  4\n",
            "h  5  4  4  4  4  4  4\n",
            "a  6  5  5  5  5  5  5\n",
            "n  7  6  6  6  6  6  6\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "for term in terms:\n",
        "    edit_d, edit_m = levenshtein_edit_distance(root_term, term)\n",
        "    print('Computing distance between root: {} and term: {}'.format(root_term,term))\n",
        "    print('Levenshtein edit distance is {}'.format(edit_d))\n",
        "    print('The complete edit distance matrix is depicted below')\n",
        "    print(edit_m)\n",
        "    print('-'*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d298480",
      "metadata": {
        "id": "5d298480"
      },
      "source": [
        "You can see from the preceding outputs that 'Believe' and 'beleive' are the closest to each other, with an edit distance of 2 and the distances between 'Believe', 'bargain', and 'Elephant' are 6, indicating a total of 6 edit operations needed. The edit distance matrices provide a more detailed insight into how the algorithm computes the distances per iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fcf05da",
      "metadata": {
        "id": "6fcf05da"
      },
      "source": [
        "#### Cosine Distance and Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7c986b",
      "metadata": {
        "id": "5e7c986b"
      },
      "source": [
        "The <code>Cosine distance</code> is a metric that can be actually derived from the Cosine similarity and vice versa. Considering we have two terms such that they are represented in their vectorized forms, <code>Cosine similarity gives us the measure of the cosine of the angle between them when they are represented as non-zero positive vectors in an inner product space</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a4eba5",
      "metadata": {
        "id": "f1a4eba5"
      },
      "source": [
        "Thus term vectors having similar orientation will have scores closer to 1 (cos0$^\\circ$) indicating the vectors are very close to each other in the same direction (near to zero degree angle between them). Term vectors having a similarity score close to 0 (cos90$^\\circ$) indicate unrelated terms with a near orthogonal angle between then. Term vectors with a similarity score close to –1 (cos180$^\\circ$) indicate terms that are completely oppositely oriented to each other"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd94bea",
      "metadata": {
        "id": "cdd94bea"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm9.png?raw=1\" width=\"730\" height=\"670\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9b47510",
      "metadata": {
        "id": "e9b47510"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm10.png?raw=1\" width=\"430\" height=\"370\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18bc9e88",
      "metadata": {
        "id": "18bc9e88"
      },
      "source": [
        "Thus you can see from the position of the vectors, the plots show more clearly how the vectors are close or far apart from each other, and the cosine of the angle between them gives us the Cosine similarity metric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f68b719",
      "metadata": {
        "id": "8f68b719"
      },
      "source": [
        "In our case, we will be using the Bag of Characters vectorization to build these term vectors, and n will be the number of unique characters across the terms under analysis. An important thing to note here is that the Cosine similarity score usually ranges from –1 to +1, but if we use the Bag of Characters–based character frequencies for terms or Bag of Words–based word frequencies for documents, the score will range from 0 to 1 because the frequency vectors can never be negative, and hence the angle between the two vectors cannot exceed 90$^\\circ$ ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1652a513",
      "metadata": {
        "id": "1652a513"
      },
      "source": [
        "The Cosine distance is complimentary to the similarity score can be computed by the formula,"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966fa175",
      "metadata": {
        "id": "966fa175"
      },
      "source": [
        "<img src=\"https://github.com/irungus/TUDA/blob/main/img/fm11.png?raw=1\" width=\"530\" height=\"470\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9fc2233",
      "metadata": {
        "id": "c9fc2233"
      },
      "source": [
        "where cd(u, v) denotes the Cosine distance between the term vectors u and v. The following function implements computation of Cosine distance based on the preceding formulae:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db39f9f3",
      "metadata": {
        "id": "db39f9f3"
      },
      "outputs": [],
      "source": [
        "def cosine_distance(u, v):\n",
        "    distance = 1.0 - (np.dot(u, v) / (np.sqrt(sum(np.square(u))) * np.sqrt(sum(np.square(v)))))\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c22df4",
      "metadata": {
        "id": "87c22df4"
      },
      "source": [
        "We will now test the similarity between our example terms using their Bag of Character representations, which we created earlier, available in the boc_root_vector and the boc_vector_terms variables, as depicted in the following code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ca92d8",
      "metadata": {
        "id": "03ca92d8",
        "outputId": "c81aec6e-d9a0-4581-f659-af2b2585d88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing similarity between root: Believe and term: beleive\n",
            "Cosine distance is -0.0\n",
            "Cosine similarity is 1.0\n",
            "----------------------------------------\n",
            "Analyzing similarity between root: Believe and term: bargain\n",
            "Cosine distance is 0.82\n",
            "Cosine similarity is 0.18000000000000005\n",
            "----------------------------------------\n",
            "Analyzing similarity between root: Believe and term: Elephan\n",
            "Cosine distance is 0.35\n",
            "Cosine similarity is 0.65\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for term, boc_term in zip(terms, boc_vector_terms):\n",
        "    print('Analyzing similarity between root: {} and term: {}'.format(root_term,term))\n",
        "    distance = round(cosine_distance(root_boc_vector, boc_term),2)\n",
        "    similarity = 1 - distance\n",
        "    print('Cosine distance is {}'.format(distance))\n",
        "    print('Cosine similarity is {}'.format(similarity))\n",
        "    print('-'*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27994ad",
      "metadata": {
        "id": "c27994ad"
      },
      "source": [
        "These vector representations do not take order of characters into account, hence the similarity between the terms \"Believe\" and \"beleive\" is 1.0 or a perfect 100 percent because it contains the same characters with the same frequency. You can see how this can be used in combination with a semantic dictionary like WordNet to provide correct spelling suggestions by suggesting semantically and syntactically correct words from a vocabulary when users type a misspelled word, by measuring the similarity between the words. You can even try our different features here instead of single character frequencies, like taking two characters at a time and computing their frequencies to build the term vectors. This takes into account some of the sequences that characters maintain in various terms. Try out different possibilities and compare the results! This distance measure works very well when measuring similarity between large documents or sentences, and we will see that in the next section when we discuss document similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a4131e4",
      "metadata": {
        "id": "1a4131e4"
      },
      "source": [
        "## Analyzing Document Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63c0144b",
      "metadata": {
        "id": "63c0144b"
      },
      "source": [
        "We analyzed similarity between terms using various similarity and distance metrics in the previous sections. We also saw how vectorization was useful so that mathematical computations become much easier, especially when computing distances between vectors. In this section, we will try to analyze similarities between documents. By now, you must already know that a document is defined as a body of text which can be comprised of sentences or paragraphs of text. For analyzing document similarity, we will be using our utils module to extract features from document using the build_feature_ matrix() function. We will vectorize documents using their TF-IDFs similarly to what we did previously when we classified text documents or summarized entire documents. Once we have the vector representations of the various documents, we will compute similarity between the documents using several distance or similarity metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f4b7c8",
      "metadata": {
        "id": "d0f4b7c8"
      },
      "source": [
        "The\n",
        "metrics we will cover in this section are as follows:\n",
        "<ul>\n",
        "<li>Cosine similarity</li>\n",
        "<li>Hellinger-Bhattacharya distance</li>\n",
        "<li>Okapi BM25 ranking</li>\n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75e3916a",
      "metadata": {
        "id": "75e3916a"
      },
      "source": [
        "We will also test our metrics on a toy corpus here with nine documents and a separate corpus with three documents, which will be our query documents. For each of these three documents, we will try to find out the most similar documents from the corpus of nine documents, which will act as our index. Consider this to be a mini-simulation of what happens in a search\n",
        "engine when you search with a sentence and the most relevant results are returned to you from its index of web pages. In our case, the queries are in the form of three documents, and relevant documents for each of these three will be returned from the index of nine documents based on similarity metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44aed983",
      "metadata": {
        "id": "44aed983"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# load the toy corpus index\n",
        "toy_corpus = [\n",
        "    'The sky is blue',\n",
        "    'The sky is blue and beautiful',\n",
        "    'Look at the bright blue sky!',\n",
        "    'Python is a great Programming language',\n",
        "    'Python and Java are popular Programming languages',\n",
        "    'Among Programming languages, both Python and Java are the most used in Analytics',\n",
        "    'The fox is quicker than the lazy dog',\n",
        "    'The dog is smarter than the fox',\n",
        "    'The dog, fox and cat are good friends'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96743e0",
      "metadata": {
        "id": "d96743e0"
      },
      "outputs": [],
      "source": [
        "# load the docs for which we will be measuring similarities\n",
        "query_docs = [\n",
        "    'The fox is definitely smarter than the dog',\n",
        "    'Java is a static typed programming language unlike Python',\n",
        "    'I love to relax under the beautiful blue sky!'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c6cd59",
      "metadata": {
        "id": "e2c6cd59"
      },
      "source": [
        "From that snippet you can see that we have various documents in our corpus index that talk about the sky, programming languages, and animals. We also have three query documents for which we want to get the most relevant documents from the toy_corpus index, based on similarity computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc04b327",
      "metadata": {
        "id": "fc04b327"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "def build_feature_matrix(documents, feature_type='frequency', ngram_range=(1, 1), min_df=0.0, max_df=1.0):\n",
        "    feature_type = feature_type.lower().strip()\n",
        "\n",
        "    if feature_type == 'binary':\n",
        "        vectorizer = CountVectorizer(binary=True, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    elif feature_type == 'frequency':\n",
        "        vectorizer = CountVectorizer(binary=False, min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    elif feature_type == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Wrong feature type entered. Possible values:'binary', 'frequency','tfidf'\")\n",
        "\n",
        "    feature_matrix = vectorizer.fit_transform(documents).astype(float)\n",
        "\n",
        "    return vectorizer, feature_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b3a85c",
      "metadata": {
        "id": "82b3a85c",
        "outputId": "6c2eb946-f861-480a-c9ba-8aab1b60af4b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pattern.en'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m WordNetLemmatizer()\n\u001b[0;32m     10\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m PorterStemmer() \n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpattern\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01men\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m suggest\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wordnet\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#loading_the_stop_words_from_nltk_library_\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pattern.en'"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "from pattern.en import suggest\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "#loading_the_stop_words_from_nltk_library_\n",
        "stop_words = set(stopwords.words('english'))#e.g. an apple => \"an\" is a stop word. a book => \"a\" is a stop word\n",
        "\n",
        "def text_preprocessing(total_text):\n",
        "    if type(total_text) is not int:\n",
        "        string = \"\"\n",
        "\n",
        "        #replace every special char with space\n",
        "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n",
        "\n",
        "        #replace multiple spaces with single space\n",
        "        total_text = re.sub('\\s+',' ', total_text)\n",
        "\n",
        "        #converting all the chars into lower case\n",
        "        total_text = total_text.lower()\n",
        "\n",
        "        #word tokenization\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        tokens = tokenizer.tokenize(total_text)\n",
        "\n",
        "        #Stemming\n",
        "        stem_words=[stemmer.stem(w) for w in tokens]\n",
        "\n",
        "        #Lemmatization\n",
        "        lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "\n",
        "        for x in range(len(lemma_words)):\n",
        "            #if_the_word_is_a_not_a_stop_word_then_retain_that_word_from_the_data\n",
        "            if not lemma_words[x] in stop_words:\n",
        "\n",
        "                #Repeating Characters\n",
        "                #lemma_words = remove_repeated_characters(lemma_words[x])\n",
        "\n",
        "                #Correcting incorrect or wrong spellings\n",
        "                #lemma_words = suggest(lemma_words)\n",
        "\n",
        "                string += lemma_words[x] + \" \"\n",
        "\n",
        "        return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ab866c",
      "metadata": {
        "id": "49ab866c"
      },
      "outputs": [],
      "source": [
        "# normalize and extract features from the toy corpus\n",
        "norm_corpus = []\n",
        "for row in range(len(toy_corpus)):\n",
        "    norm_corpus.append(text_preprocessing(toy_corpus[row]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85af4b78",
      "metadata": {
        "id": "85af4b78"
      },
      "outputs": [],
      "source": [
        "print(norm_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "165898fe",
      "metadata": {
        "id": "165898fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ff624c",
      "metadata": {
        "id": "a6ff624c"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer, tfidf_features = build_feature_matrix(norm_corpus, feature_type='tfidf', ngram_range=(1, 1), min_df=0.0,\n",
        "                                                        max_df=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce27cca",
      "metadata": {
        "id": "5ce27cca"
      },
      "outputs": [],
      "source": [
        "print(tfidf_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff29f4ee",
      "metadata": {
        "id": "ff29f4ee"
      },
      "outputs": [],
      "source": [
        "print(tfidf_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8ceb4c6",
      "metadata": {
        "id": "b8ceb4c6"
      },
      "outputs": [],
      "source": [
        "# normalize and extract features from the query corpus\n",
        "norm_query_docs = []\n",
        "for row in range(len(query_docs)):\n",
        "    norm_query_docs.append(text_preprocessing(query_docs[row]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c213d6b",
      "metadata": {
        "id": "4c213d6b"
      },
      "outputs": [],
      "source": [
        "query_docs_tfidf = tfidf_vectorizer.transform(norm_query_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53da627",
      "metadata": {
        "id": "f53da627"
      },
      "outputs": [],
      "source": [
        "print(query_docs_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191252eb",
      "metadata": {
        "id": "191252eb"
      },
      "source": [
        "Now that we have our documents normalized and vectorized with TF-IDF–based vector representations, we will look at how to compute similarity for each of the metrics, namely:\n",
        "<ul>\n",
        "    <li>Cosine similarity</li>\n",
        "    <li>Hellinger-Bhattacharya distance</li>\n",
        "    <li>Okapi BM25 ranking</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "421a0f6e",
      "metadata": {
        "id": "421a0f6e"
      },
      "source": [
        "## Cosine Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f3572b",
      "metadata": {
        "id": "25f3572b"
      },
      "source": [
        "We have seen the concepts with regards to computing Cosine similarity and also implemented the same for term similarity. Here, we will reuse the same concepts to compute the Cosine similarity scores for documents instead of terms. The document vectors will be the Bag of Words model–based vectors with TF-IDF values instead of term frequencies. We have also taken only unigrams here, but you can experiment with bigrams and so on as document features during the vectorization process. For each of the three query documents, we will compute its similarity with the nine documents in toy_corpus and return the n most similar documents where n is a user input parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "834d4197",
      "metadata": {
        "id": "834d4197"
      },
      "source": [
        "We will define a function that will take in the vectorized corpus and the document corpus for which we want to compute similarities. We will get the similarity scores using the dot product operation as before and finally we will sort them in reverse order and get the top n documents with the highest similarity score. The following function implements this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5862199",
      "metadata": {
        "id": "f5862199"
      },
      "outputs": [],
      "source": [
        "def compute_cosine_similarity(doc_features, corpus_features, top_n=3):\n",
        "    # get document vectors\n",
        "    doc_features = doc_features.toarray()[0]\n",
        "    corpus_features = corpus_features.toarray()\n",
        "    # compute similarities\n",
        "    similarity = np.dot(doc_features, corpus_features.T)\n",
        "    # get docs with highest similarity scores\n",
        "    top_docs = similarity.argsort()[::-1][:top_n]\n",
        "    top_docs_with_score = [(index, round(similarity[index], 3)) for index in top_docs]\n",
        "    return top_docs_with_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17b7c03",
      "metadata": {
        "id": "c17b7c03"
      },
      "source": [
        "In that function, corpus_features are the vectorized documents belonging to the toy_corpus index from which we want to retrieve similar documents. These documents will be retrieved on the basis of their similarity score with doc_features, which basically represents the vectorized document belonging to each of the query_docs, as shown in the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a7efb2",
      "metadata": {
        "id": "55a7efb2"
      },
      "outputs": [],
      "source": [
        "print('Document Similarity Analysis using Cosine Similarity')\n",
        "print('='*60)\n",
        "print('\\n')\n",
        "\n",
        "for index, doc in enumerate(query_docs):\n",
        "    doc_tfidf = query_docs_tfidf[index]\n",
        "    top_similar_docs = compute_cosine_similarity(doc_tfidf,tfidf_features,top_n=3)\n",
        "    print('Document',index+1 ,':', doc)\n",
        "    print('Top', len(top_similar_docs)+1, 'similar docs:')\n",
        "\n",
        "    print('+++'*20)\n",
        "\n",
        "    for doc_index, sim_score in top_similar_docs:\n",
        "        print('Doc num: {} Similarity Score: {}\\nDoc: {}'.format(doc_index+1,sim_score, toy_corpus[doc_index]))\n",
        "        print('-'*40)\n",
        "\n",
        "    print('\\n'*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a2aea2",
      "metadata": {
        "id": "51a2aea2"
      },
      "source": [
        "The preceding output depicts the top two most relevant documents for each of the query documents based on Cosine similarity scores, and you can see that the outputs are quite what were expected. Documents about animals are similar to the document\n",
        "that mentions the fox and the dog; documents about Python and Java are most similar to the query document talking about them; and the beautiful blue sky is indeed similar to documents that talk about the sky being blue and beautiful!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae9baa0",
      "metadata": {
        "id": "5ae9baa0"
      },
      "source": [
        "Also note the Cosine similarity scores in the preceding outputs, where 1.0 indicates perfect similarity, 0.0 indicates no similarity, and any score between them indicates some level of similarity based on how large that score is. For instance, in the last example, the main document vectors are ['sky', 'blue', 'beautiful'] and because they all match with the first document from the toy corpus, we get a 1.0 or 100 percent similarity score, and only ['sky', 'blue'] match from the second most similar document, and we get a 0.72 or 72 percent similarity score. And you should remember our discussion from earlier where I mentioned briefly that Cosine similarity using Bag of Words–based vectors only looks at token weights and does not consider order or sequence of the terms, which is quite desirable in large documents because the same content may be depicted in different ways, and capturing sequences there might lead to loss of information due to unwanted mismatches."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c3a5a5",
      "metadata": {
        "id": "73c3a5a5"
      },
      "source": [
        "We recommend using scikit-learn’s cosine_similarity() utility function, which you can find under the sklearn.metrics.pairwise module. It uses similar logic as our implementation but is much more optimized and performs well on large corpora of documents. You can also use gensim’s similarities module or the cossim() function directly available in the gensim.matutils module."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf31461f",
      "metadata": {
        "id": "bf31461f"
      },
      "source": [
        "## Hellinger-Bhattacharya Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4572d47",
      "metadata": {
        "id": "e4572d47"
      },
      "source": [
        "The Hellinger-Bhattacharya distance (HB-distance) is also called the Hellinger distance or the Bhattacharya distance. The Bhattacharya distance, originally introduced by A. Bhattacharya, is used to measure the similarity between two discrete or continuous probability distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edcd3734",
      "metadata": {
        "id": "edcd3734"
      },
      "source": [
        "HB-distance is computable for both continuous and discrete probability distributions. In our case, we will be using the TF-IDF–based vectors as our document distributions. This makes it discrete distributions because we have specific TF-IDF values for specific feature terms, unlike continuous distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0051d6f4",
      "metadata": {
        "id": "0051d6f4"
      },
      "source": [
        " As with the previous computation of Cosine similarity, we will build our function on the same principles; basically we will accept as input a corpus of document vectors and a single document vector for which we want to get the n most similar\n",
        "documents from the corpus based on their HB-distances. The function implements the preceding concepts in Python in the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6bd409c",
      "metadata": {
        "id": "a6bd409c"
      },
      "outputs": [],
      "source": [
        "def compute_hellinger_bhattacharya_distance(doc_features, corpus_features, top_n=3):\n",
        "    # get document vectors\n",
        "    doc_features = doc_features.toarray()[0]\n",
        "    corpus_features = corpus_features.toarray()\n",
        "    # compute hb distances\n",
        "    distance = np.hstack(np.sqrt(0.5 *np.sum(np.square(np.sqrt(doc_features) - np.sqrt(corpus_features)), axis=1)))\n",
        "    # get docs with lowest distance scores\n",
        "    top_docs = distance.argsort()[:top_n]\n",
        "    top_docs_with_score = [(index, round(distance[index], 3)) for index in top_docs]\n",
        "    return top_docs_with_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4615f9",
      "metadata": {
        "id": "bf4615f9"
      },
      "source": [
        "From the preceding implementation, you case see that we sort the documents based on their scores in ascending order, unlike Cosine similarity, where 1.0 indicates perfect similarity—since this is a distance metric between distributions, a value of 0 indicates perfect similarity, and higher values indicate some dissimilarity being present. We can now apply this function to our example corpora, compute their HB-distances, and see the results in the following snippet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93b4ae1",
      "metadata": {
        "id": "d93b4ae1"
      },
      "outputs": [],
      "source": [
        "# get Hellinger-Bhattacharya distance based similarities for our example documents\n",
        "\n",
        "print('Document Similarity Analysis using Hellinger-Bhattacharya distance')\n",
        "print('\\n')\n",
        "\n",
        "for index, doc in enumerate(query_docs):\n",
        "    doc_tfidf = query_docs_tfidf[index]\n",
        "    top_similar_docs = compute_hellinger_bhattacharya_distance(doc_tfidf,tfidf_features,top_n=3)\n",
        "    print('Document',index+1 ,':', doc)\n",
        "    print('Top', len(top_similar_docs), 'similar docs:')\n",
        "\n",
        "    print('++'*20)\n",
        "\n",
        "    for doc_index, sim_score in top_similar_docs:\n",
        "        print('Doc num: {} Distance Score: {}\\nDoc: {}'.format(doc_index+1,sim_score, toy_corpus[doc_index]))\n",
        "        print('-'*40)\n",
        "\n",
        "    print('\\n'*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab2f7b7",
      "metadata": {
        "id": "4ab2f7b7"
      },
      "source": [
        "You can see from the preceding outputs that documents with lower HB-distance scores are more similar to the query documents, and the result documents are quite similar to what we obtained using Cosine similarity. Compare the results and try out these functions with larger corpora! I recommend using gensim’s hellinger() function, available in the gensim.matutils module (which uses the same logic as our preceding function) when building large-scale systems for analyzing similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5074dd8",
      "metadata": {
        "id": "d5074dd8"
      },
      "source": [
        "## Okapi BM25 Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28bcff12",
      "metadata": {
        "id": "28bcff12"
      },
      "source": [
        "There are several techniques that are quite popular in information retrieval and search engines, including PageRank and Okapi BM25. The acronym BM stands for best matching. This technique is also known as BM25, but for the sake of completeness I refer to it as Okapi BM25, because originally although the concepts behind the BM25 function were merely theoretical, the City University in London built the Okapi Information Retrieval system in the 1980s–90s, which implemented this technique to retrieve documents on actual real-world data. This technique can also be called a framework or model based on probabilistic relevancy and was developed by several people in the 1970s–80s, including computer scientists S. Robertson and K. Jones. There are several functions that rank documents based on different factors, and BM25 is one of them. Its newer variant is BM25F; other variants include BM15 and BM25+."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4beafaca",
      "metadata": {
        "id": "4beafaca"
      },
      "source": [
        "The Okapi BM25 can be formally defined as a document ranking and retrieval function based on a Bag of Words–based model for retrieving relevant documents based on a user input query. This query can be itself a document containing a sentence or collection of sentences, or it can even be a couple of words. The Okapi BM25 is actually not just a single function but is a framework consisting of a whole collection of scoring functions combined together."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c406f6",
      "metadata": {
        "id": "97c406f6"
      },
      "source": [
        "There are several steps we must go through to successfully implement and compute BM25 scores for documents:\n",
        "<ol>\n",
        "<li>Build a function to get inverse document frequency (IDF) values for terms in corpus.</li>\n",
        "<li>Build a function for computing BM25 scores for query document and corpus documents.</li>\n",
        "<li>Get Bag of Words–based features for corpus documents and query documents.</li>\n",
        "<li>Compute average length of corpus documents and IDFs of the terms in the corpus documents using function from point 1.</li>\n",
        "<li>Compute BM25 scores, rank relevant documents, and fetch the n most relevant documents for each query document\n",
        "using the function in point 2.</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a94342",
      "metadata": {
        "id": "f5a94342"
      },
      "source": [
        "We will start with implementing a function to extract and compute inverse document frequencies of all the terms in a corpus of documents by using its Bag of Words features, which will contain the term frequencies, and then convert them to IDFs using the formula mentioned earlier. The following function implements this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0401ca03",
      "metadata": {
        "id": "0401ca03"
      },
      "outputs": [],
      "source": [
        "import scipy.sparse as sp\n",
        "def compute_corpus_term_idfs(corpus_features, norm_corpus):\n",
        "    dfs = np.diff(sp.csc_matrix(corpus_features, copy=True).indptr)\n",
        "    dfs = 1 + dfs # to smoothen idf later\n",
        "    total_docs = 1 + len(norm_corpus)\n",
        "    idfs = 1.0 + np.log(float(total_docs) / dfs)\n",
        "    return idfs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "232e1d65",
      "metadata": {
        "id": "232e1d65"
      },
      "source": [
        "We will now implement the main function for computing BM25 score for all the documents in our corpus based on the query document and retrieving the top n relevant documents from the corpus based on their BM25 score. The following function implements the BM25 scoring framework:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da83d9a4",
      "metadata": {
        "id": "da83d9a4"
      },
      "outputs": [],
      "source": [
        "def compute_bm25_similarity(doc_features, corpus_features,corpus_doc_lengths, avg_doc_length,term_idfs, k1=1.5, b=0.75, top_n=3):\n",
        "    # get corpus bag of words features\n",
        "    corpus_features = corpus_features.toarray()\n",
        "    # convert query document features to binary features\n",
        "    # this is to keep a note of which terms exist per document\n",
        "    doc_features = doc_features.toarray()[0]\n",
        "    doc_features[doc_features >= 1] = 1\n",
        "\n",
        "    # compute the document idf scores for present terms\n",
        "    doc_idfs = doc_features * term_idfs\n",
        "    # compute numerator expression in BM25 equation\n",
        "    numerator_coeff = corpus_features * (k1 + 1)\n",
        "    numerator = np.multiply(doc_idfs, numerator_coeff)\n",
        "    # compute denominator expression in BM25 equation\n",
        "    denominator_coeff = k1 * (1 - b +(b * (corpus_doc_lengths /avg_doc_length)))\n",
        "\n",
        "    denominator_coeff = np.vstack(denominator_coeff)\n",
        "    denominator = corpus_features + denominator_coeff\n",
        "    # compute the BM25 score combining the above equations\n",
        "    bm25_scores = np.sum(np.divide(numerator,denominator),axis=1)\n",
        "\n",
        "    # get top n relevant docs with highest BM25 score\n",
        "    top_docs = bm25_scores.argsort()[::-1][:top_n]\n",
        "    top_docs_with_score = [(index, round(bm25_scores[index], 3))for index in top_docs]\n",
        "    return top_docs_with_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480d9830",
      "metadata": {
        "id": "480d9830"
      },
      "outputs": [],
      "source": [
        "# build bag of words based features first\n",
        "vectorizer, corpus_features = build_feature_matrix(norm_corpus,feature_type='frequency')\n",
        "query_docs_features = vectorizer.transform(norm_query_docs)\n",
        "# get average document length of the corpus (avgdl)\n",
        "doc_lengths = [len(doc.split()) for doc in norm_corpus]\n",
        "avg_dl = np.average(doc_lengths)\n",
        "\n",
        "# Get the corpus term idfs\n",
        "corpus_term_idfs = compute_corpus_term_idfs(corpus_features,norm_corpus)\n",
        "\n",
        "# analyze document similarity using BM25 framework\n",
        "print('Document Similarity Analysis using BM25')\n",
        "print('\\n')\n",
        "\n",
        "for index, doc in enumerate(query_docs):\n",
        "    doc_features = query_docs_features[index]\n",
        "    top_similar_docs = compute_bm25_similarity(doc_features,corpus_features,doc_lengths,avg_dl,corpus_term_idfs,k1=1.5,\n",
        "                                               b=0.75,top_n=4)\n",
        "\n",
        "    print('Document',index+1 ,':', doc)\n",
        "    print('Top', len(top_similar_docs), 'similar docs:')\n",
        "    print('+'*40)\n",
        "\n",
        "    for doc_index, sim_score in top_similar_docs:\n",
        "        print('Doc num: {} BM25 Score: {}\\nDoc: {}'.format(doc_index+1,sim_score, toy_corpus[doc_index]))\n",
        "        print('-'*40)\n",
        "\n",
        "    print('\\n'*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "951946d4",
      "metadata": {
        "id": "951946d4"
      },
      "source": [
        "You can now see how for each query document, we get expected and relevant documents that have similar concepts just like the query documents. You can see that the results are quite similar to the previous methods—because, of course, they are all similarity and ranking metrics and are expected to return similar results. Notice the BM25 scores of the relevant documents. The higher the score, the more relevant is the document. Unfortunately, I was not able to find any production-ready scalable implementation of the BM25 ranking framework in nltk or scikit-learn. However, gensim seems to have a bm25 module under the gensim.summarization package and if you are interested you can give it a try. But the core of the algorithm is based on what we implemented, and this should work pretty well on its own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "090b5077",
      "metadata": {
        "id": "090b5077"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}